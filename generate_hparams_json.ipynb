{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Hyperparameters(learning_rate=0.00010352472568688982, one_minus_beta1=0.02742330411536369, beta2=0.999, warmup_factor=0.05, weight_decay=0.14194124966570845, label_smoothing=0.2, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.0009554263254837416, one_minus_beta1=0.08767264061338312, beta2=0.99, warmup_factor=0.05, weight_decay=0.01950318659958426, label_smoothing=0.1, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.0002366315233112939, one_minus_beta1=0.017305996309581857, beta2=0.99, warmup_factor=0.05, weight_decay=0.358796133013872, label_smoothing=0.2, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.001329868220562242, one_minus_beta1=0.10849784490183723, beta2=0.99, warmup_factor=0.05, weight_decay=0.013415189274868547, label_smoothing=0.2, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.007657804564479436, one_minus_beta1=0.018474843193311084, beta2=0.9, warmup_factor=0.05, weight_decay=0.03599507884441202, label_smoothing=0.1, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.0034662453048871942, one_minus_beta1=0.12329779973031552, beta2=0.999, warmup_factor=0.05, weight_decay=0.009741818387072209, label_smoothing=0.2, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.0005003918088353682, one_minus_beta1=0.052868308504766766, beta2=0.9, warmup_factor=0.05, weight_decay=0.015615014538597293, label_smoothing=0.2, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.00010868344914239434, one_minus_beta1=0.05095093967496511, beta2=0.9, warmup_factor=0.05, weight_decay=0.1329983427667685, label_smoothing=0.1, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.00435632345031001, one_minus_beta1=0.039565609666258376, beta2=0.9, warmup_factor=0.05, weight_decay=0.67305554368052, label_smoothing=0.2, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.009813249295987805, one_minus_beta1=0.04320905474501441, beta2=0.99, warmup_factor=0.05, weight_decay=0.040776760432347, label_smoothing=0.1, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.07758862577375368, beta2=0.99, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.004640611793681601, one_minus_beta1=0.04458099897099783, beta2=0.99, warmup_factor=0.05, weight_decay=0.008693223345430781, label_smoothing=0.1, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.006304156439459244, one_minus_beta1=0.08842322859774977, beta2=0.9, warmup_factor=0.05, weight_decay=0.17160921709287533, label_smoothing=0.2, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.002551570379975017, one_minus_beta1=0.1421215743266082, beta2=0.9, warmup_factor=0.05, weight_decay=0.08618471752833365, label_smoothing=0.1, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.007846282500477477, one_minus_beta1=0.029778889350926263, beta2=0.9, warmup_factor=0.05, weight_decay=0.73406429272016, label_smoothing=0.2, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.00033912171388383205, one_minus_beta1=0.032336812779532875, beta2=0.9, warmup_factor=0.05, weight_decay=0.01091689718711528, label_smoothing=0.2, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.00017934631249680855, one_minus_beta1=0.04047534986540376, beta2=0.9, warmup_factor=0.05, weight_decay=0.8874953466044864, label_smoothing=0.1, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.0004388216202218091, one_minus_beta1=0.011926975775142115, beta2=0.99, warmup_factor=0.05, weight_decay=0.3977375056989399, label_smoothing=0.1, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.0003774140917333739, one_minus_beta1=0.03780701273448289, beta2=0.999, warmup_factor=0.05, weight_decay=0.18920569423026226, label_smoothing=0.2, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.0004452703878283557, one_minus_beta1=0.04333201245579045, beta2=0.999, warmup_factor=0.05, weight_decay=0.10764489676476119, label_smoothing=0.1, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.003099451526942006, one_minus_beta1=0.06181168275666899, beta2=0.9, warmup_factor=0.05, weight_decay=0.01613145683725297, label_smoothing=0.2, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.00013266386376279386, one_minus_beta1=0.024338165842659493, beta2=0.9, warmup_factor=0.05, weight_decay=0.8731733774313366, label_smoothing=0.2, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.00010054778177688589, one_minus_beta1=0.013477097323359031, beta2=0.999, warmup_factor=0.05, weight_decay=0.012638327613865154, label_smoothing=0.1, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.005664537660802364, one_minus_beta1=0.022733672445259905, beta2=0.99, warmup_factor=0.05, weight_decay=0.04983736868450118, label_smoothing=0.2, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.0009461790736773607, one_minus_beta1=0.013944581616283223, beta2=0.999, warmup_factor=0.05, weight_decay=0.0412214361848658, label_smoothing=0.1, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.0018153997976781942, one_minus_beta1=0.015982399575739353, beta2=0.9, warmup_factor=0.05, weight_decay=0.05435484951861185, label_smoothing=0.2, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.0008177402338803047, one_minus_beta1=0.01037671162895293, beta2=0.9, warmup_factor=0.05, weight_decay=0.1053349873037458, label_smoothing=0.1, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.00019766560226064676, one_minus_beta1=0.07004395946742636, beta2=0.999, warmup_factor=0.05, weight_decay=0.012300240728935494, label_smoothing=0.1, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.006586191794546985, one_minus_beta1=0.08594595301625073, beta2=0.999, warmup_factor=0.05, weight_decay=0.008506678888091451, label_smoothing=0.1, dropout_rate=0.1),\n",
       " Hyperparameters(learning_rate=0.0009981701890848006, one_minus_beta1=0.017553635461744672, beta2=0.9, warmup_factor=0.05, weight_decay=0.5909164983742032, label_smoothing=0.2, dropout_rate=0.1)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from algorithmic_efficiency import halton\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "tuning_search_space = \"tuning_search_space_caspr_adaptive_full_matrix.json\"\n",
    "num_tuning_trials = 30\n",
    "with open(tuning_search_space, 'r', encoding='UTF-8') as search_space_file:\n",
    "      tuning_search_space = halton.generate_search(\n",
    "          json.load(search_space_file), num_tuning_trials)\n",
    "      \n",
    "tuning_search_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##imagenet generatin\n",
    "\n",
    "import collections\n",
    "\n",
    "all_hyperparameter_names = [\"learning_rate\",\"one_minus_beta1\",\"beta2\",\"warmup_factor\",\"weight_decay\",\"label_smoothing\",\"dropout_rate\"]\n",
    "Hyperparameters = collections.namedtuple('Hyperparameters', all_hyperparameter_names)\n",
    "tuning_search_space = [Hyperparameters(learning_rate=0.0002366315233112939, one_minus_beta1=0.017305996309581857, beta2=0.99, warmup_factor=0.05, weight_decay=0.358796133013872, label_smoothing=0.2, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.007657804564479436, one_minus_beta1=0.018474843193311084, beta2=0.9, warmup_factor=0.05, weight_decay=0.03599507884441202, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.003099451526942006, one_minus_beta1=0.06181168275666899, beta2=0.9, warmup_factor=0.05, weight_decay=0.01613145683725297, label_smoothing=0.2, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.0009554263254837416, one_minus_beta1=0.08767264061338312, beta2=0.99, warmup_factor=0.05, weight_decay=0.01950318659958426, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.0009461790736773607, one_minus_beta1=0.013944581616283223, beta2=0.999, warmup_factor=0.05, weight_decay=0.0412214361848658, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.00013266386376279386, one_minus_beta1=0.024338165842659493, beta2=0.9, warmup_factor=0.05, weight_decay=0.8731733774313366, label_smoothing=0.2, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.0004388216202218091, one_minus_beta1=0.011926975775142115, beta2=0.99, warmup_factor=0.05, weight_decay=0.3977375056989399, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.00010868344914239434, one_minus_beta1=0.05095093967496511, beta2=0.9, warmup_factor=0.05, weight_decay=0.1329983427667685, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.07758862577375368, beta2=0.99, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.0018153997976781942, one_minus_beta1=0.015982399575739353, beta2=0.9, warmup_factor=0.05, weight_decay=0.05435484951861185, label_smoothing=0.2, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.001329868220562242, one_minus_beta1=0.10849784490183723, beta2=0.99, warmup_factor=0.05, weight_decay=0.013415189274868547, label_smoothing=0.2, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.00010054778177688589, one_minus_beta1=0.013477097323359031, beta2=0.999, warmup_factor=0.05, weight_decay=0.012638327613865154, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.006304156439459244, one_minus_beta1=0.08842322859774977, beta2=0.9, warmup_factor=0.05, weight_decay=0.17160921709287533, label_smoothing=0.2, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.00019766560226064676, one_minus_beta1=0.07004395946742636, beta2=0.999, warmup_factor=0.05, weight_decay=0.012300240728935494, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.009813249295987805, one_minus_beta1=0.04320905474501441, beta2=0.99, warmup_factor=0.05, weight_decay=0.040776760432347, label_smoothing=0.1, dropout_rate=0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divided_hparams  [2, 2, 3, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# def sample_hyperparameters():\n",
    "#     sampled_params = {}\n",
    "#     for param, values in search_space.items():\n",
    "#         sampled_params[param] = np.random.choice(values)\n",
    "#     return sampled_params\n",
    "import json\n",
    "\n",
    "def divide_hparams(hparams_list, hparams_per_json_list):\n",
    "    divided_hparams = []  # This will store the final divided hyperparameters\n",
    "    start_index = 0  # Start index for slicing the hparams_list\n",
    "    \n",
    "    for count in hparams_per_json_list:\n",
    "        # Slice the hparams_list from the current start index by the count specified in hparams_per_json_list\n",
    "        end_index = start_index + count\n",
    "        slice_hparams = hparams_list[start_index:end_index]\n",
    "        \n",
    "        # Add the sliced hyperparameters to the divided_hparams list\n",
    "        divided_hparams.append(slice_hparams)\n",
    "        \n",
    "        # Update the start_index for the next slice\n",
    "        start_index = end_index\n",
    "    \n",
    "    return divided_hparams\n",
    "\n",
    "\n",
    "def generate_json_files(num_tpus,tuning_search_space):\n",
    "    num_hparams_per_json = len(tuning_search_space)//num_tpus\n",
    "    # hparams_per_json_list = [num_hparams_per_json]*num_tpus\n",
    "    # if len(tuning_search_space)%num_tpus != 0:\n",
    "    #     hparams_per_json_list   += [len(tuning_search_space)%num_tpus ]\n",
    "    #list for caspr-adaptive\n",
    "    # hparams_per_json_list = [1,1,1,2,2,4,4]\n",
    "    # #list for shampoo\n",
    "    # hparams_per_json_list = [1,1,1,1,3,4,4]\n",
    "    # # list for nadamw 0.375\n",
    "    # hparams_per_json_list = [3,3,3,3,3]\n",
    "    # # list for nadamw 0.75\n",
    "    # hparams_per_json_list = [5,5,5]\n",
    "    # # list for adamw 0.75\n",
    "    # hparams_per_json_list = [5,5,5]\n",
    "    # # list for adamw 0.375\n",
    "    # hparams_per_json_list = [3,3,3,3,3]\n",
    "\n",
    "    #list for imagenet\n",
    "    # list for caspr_adaptive (2tpuv2, 3 tpuv3s)\n",
    "    hparams_per_json_list = [2,2,3,4,4]\n",
    "\n",
    "    # #list for shampoo (3tpuv2, 2tpuv3s)\n",
    "    # hparams_per_json_list = [2,2,3,4,4]\n",
    "\n",
    "    num_tpus = len(hparams_per_json_list)\n",
    "    tuning_search_space = [ hparam._asdict() for hparam in tuning_search_space]\n",
    "    divided_hparams = divide_hparams(tuning_search_space,hparams_per_json_list)\n",
    "    print(\"divided_hparams \", [len(hparams) for hparams in divided_hparams])\n",
    "    for i in range(num_tpus):\n",
    "        hparams_in_json = divided_hparams[i]\n",
    "        # file_name = f\"caspr_adaptive_jsons/tuning_search_space_caspr_adaptive_{i}.json\"\n",
    "        # file_name = f\"shampoo_jsons/tuning_search_space_shampoo_{i}.json\"\n",
    "        # file_name = f\"adamw_0.375_jsons/tuning_search_space_adamw_0.375_{i}.json\"\n",
    "        file_name = f\"caspr_adaptive_imagenet_jsons/tuning_search_space_caspr_adaptive_{i}.json\"\n",
    "        with open(file_name, 'w') as f:\n",
    "            json.dump(hparams_in_json, f, indent=4)\n",
    "\n",
    "\n",
    "# Adjust the `num_files` according to the number of TPUs you want to use\n",
    "num_tpus = 5  # Example, adjust as necessary\n",
    "generate_json_files(num_tpus,tuning_search_space)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imagenet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 4, 4, 3]\n",
      "divided_hparams  [4, 4, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# def sample_hyperparameters():\n",
    "#     sampled_params = {}\n",
    "#     for param, values in search_space.items():\n",
    "#         sampled_params[param] = np.random.choice(values)\n",
    "#     return sampled_params\n",
    "\n",
    "def divide_hparams(hparams_list, hparams_per_json_list):\n",
    "    divided_hparams = []  # This will store the final divided hyperparameters\n",
    "    start_index = 0  # Start index for slicing the hparams_list\n",
    "    \n",
    "    for count in hparams_per_json_list:\n",
    "        # Slice the hparams_list from the current start index by the count specified in hparams_per_json_list\n",
    "        end_index = start_index + count\n",
    "        slice_hparams = hparams_list[start_index:end_index]\n",
    "        \n",
    "        # Add the sliced hyperparameters to the divided_hparams list\n",
    "        divided_hparams.append(slice_hparams)\n",
    "        \n",
    "        # Update the start_index for the next slice\n",
    "        start_index = end_index\n",
    "    \n",
    "    return divided_hparams\n",
    "\n",
    "\n",
    "def generate_json_files(num_tpus,tuning_search_space):\n",
    "    num_hparams_per_json = int(math.ceil(len(tuning_search_space)/num_tpus))\n",
    "    hparams_per_json_list = [num_hparams_per_json]*(num_tpus-1)\n",
    "    if len(tuning_search_space)%num_tpus != 0:\n",
    "        hparams_per_json_list   += [len(tuning_search_space)%num_tpus ]\n",
    "    tuning_search_space = [ hparam._asdict() for hparam in tuning_search_space]\n",
    "    print(hparams_per_json_list)\n",
    "    divided_hparams = divide_hparams(tuning_search_space,hparams_per_json_list)\n",
    "    print(\"divided_hparams \", [len(hparams) for hparams in divided_hparams])\n",
    "    for i in range(num_tpus):\n",
    "        hparams_in_json = divided_hparams[i]\n",
    "        file_name = f\"tuning_search_space_caspr_adaptive_full_matrix_imagenet2_{i}.json\"\n",
    "        with open(file_name, 'w') as f:\n",
    "            json.dump(hparams_in_json, f, indent=4)\n",
    "\n",
    "\n",
    "# Adjust the `num_files` according to the number of TPUs you want to use\n",
    "num_tpus = 4  # Example, adjust as necessary\n",
    "\n",
    "generate_json_files(num_tpus,tuning_search_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ogbg 30 hparam collection\n",
    "import collections\n",
    "\n",
    "all_hyperparameter_names = [\"learning_rate\",\"one_minus_beta1\",\"beta2\",\"warmup_factor\",\"weight_decay\",\"label_smoothing\",\"dropout_rate\"]\n",
    "Hyperparameters = collections.namedtuple('Hyperparameters', all_hyperparameter_names)\n",
    "tuning_search_space = [Hyperparameters(learning_rate=0.00010352472568688982, one_minus_beta1=0.02742330411536369, beta2=0.999, warmup_factor=0.05, weight_decay=0.14194124966570845, label_smoothing=0.2, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.0009554263254837416, one_minus_beta1=0.08767264061338312, beta2=0.99, warmup_factor=0.05, weight_decay=0.01950318659958426, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.0002366315233112939, one_minus_beta1=0.017305996309581857, beta2=0.99, warmup_factor=0.05, weight_decay=0.358796133013872, label_smoothing=0.2, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.001329868220562242, one_minus_beta1=0.10849784490183723, beta2=0.99, warmup_factor=0.05, weight_decay=0.013415189274868547, label_smoothing=0.2, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.007657804564479436, one_minus_beta1=0.018474843193311084, beta2=0.9, warmup_factor=0.05, weight_decay=0.03599507884441202, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.0034662453048871942, one_minus_beta1=0.12329779973031552, beta2=0.999, warmup_factor=0.05, weight_decay=0.009741818387072209, label_smoothing=0.2, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.0005003918088353682, one_minus_beta1=0.052868308504766766, beta2=0.9, warmup_factor=0.05, weight_decay=0.015615014538597293, label_smoothing=0.2, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.00010868344914239434, one_minus_beta1=0.05095093967496511, beta2=0.9, warmup_factor=0.05, weight_decay=0.1329983427667685, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.00435632345031001, one_minus_beta1=0.039565609666258376, beta2=0.9, warmup_factor=0.05, weight_decay=0.67305554368052, label_smoothing=0.2, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.009813249295987805, one_minus_beta1=0.04320905474501441, beta2=0.99, warmup_factor=0.05, weight_decay=0.040776760432347, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.07758862577375368, beta2=0.99, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.004640611793681601, one_minus_beta1=0.04458099897099783, beta2=0.99, warmup_factor=0.05, weight_decay=0.008693223345430781, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.006304156439459244, one_minus_beta1=0.08842322859774977, beta2=0.9, warmup_factor=0.05, weight_decay=0.17160921709287533, label_smoothing=0.2, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.002551570379975017, one_minus_beta1=0.1421215743266082, beta2=0.9, warmup_factor=0.05, weight_decay=0.08618471752833365, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.007846282500477477, one_minus_beta1=0.029778889350926263, beta2=0.9, warmup_factor=0.05, weight_decay=0.73406429272016, label_smoothing=0.2, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.00033912171388383205, one_minus_beta1=0.032336812779532875, beta2=0.9, warmup_factor=0.05, weight_decay=0.01091689718711528, label_smoothing=0.2, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.00017934631249680855, one_minus_beta1=0.04047534986540376, beta2=0.9, warmup_factor=0.05, weight_decay=0.8874953466044864, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.0004388216202218091, one_minus_beta1=0.011926975775142115, beta2=0.99, warmup_factor=0.05, weight_decay=0.3977375056989399, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.0003774140917333739, one_minus_beta1=0.03780701273448289, beta2=0.999, warmup_factor=0.05, weight_decay=0.18920569423026226, label_smoothing=0.2, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.0004452703878283557, one_minus_beta1=0.04333201245579045, beta2=0.999, warmup_factor=0.05, weight_decay=0.10764489676476119, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.003099451526942006, one_minus_beta1=0.06181168275666899, beta2=0.9, warmup_factor=0.05, weight_decay=0.01613145683725297, label_smoothing=0.2, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.00013266386376279386, one_minus_beta1=0.024338165842659493, beta2=0.9, warmup_factor=0.05, weight_decay=0.8731733774313366, label_smoothing=0.2, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.00010054778177688589, one_minus_beta1=0.013477097323359031, beta2=0.999, warmup_factor=0.05, weight_decay=0.012638327613865154, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.005664537660802364, one_minus_beta1=0.022733672445259905, beta2=0.99, warmup_factor=0.05, weight_decay=0.04983736868450118, label_smoothing=0.2, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.0009461790736773607, one_minus_beta1=0.013944581616283223, beta2=0.999, warmup_factor=0.05, weight_decay=0.0412214361848658, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.0018153997976781942, one_minus_beta1=0.015982399575739353, beta2=0.9, warmup_factor=0.05, weight_decay=0.05435484951861185, label_smoothing=0.2, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.0008177402338803047, one_minus_beta1=0.01037671162895293, beta2=0.9, warmup_factor=0.05, weight_decay=0.1053349873037458, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.00019766560226064676, one_minus_beta1=0.07004395946742636, beta2=0.999, warmup_factor=0.05, weight_decay=0.012300240728935494, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.006586191794546985, one_minus_beta1=0.08594595301625073, beta2=0.999, warmup_factor=0.05, weight_decay=0.008506678888091451, label_smoothing=0.1, dropout_rate=0.1),\n",
    " Hyperparameters(learning_rate=0.0009981701890848006, one_minus_beta1=0.017553635461744672, beta2=0.9, warmup_factor=0.05, weight_decay=0.5909164983742032, label_smoothing=0.2, dropout_rate=0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divided_hparams  [4, 4, 6, 8, 8]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# def sample_hyperparameters():\n",
    "#     sampled_params = {}\n",
    "#     for param, values in search_space.items():\n",
    "#         sampled_params[param] = np.random.choice(values)\n",
    "#     return sampled_params\n",
    "import json\n",
    "\n",
    "def divide_hparams(hparams_list, hparams_per_json_list):\n",
    "    divided_hparams = []  # This will store the final divided hyperparameters\n",
    "    start_index = 0  # Start index for slicing the hparams_list\n",
    "    \n",
    "    for count in hparams_per_json_list:\n",
    "        # Slice the hparams_list from the current start index by the count specified in hparams_per_json_list\n",
    "        end_index = start_index + count\n",
    "        slice_hparams = hparams_list[start_index:end_index]\n",
    "        \n",
    "        # Add the sliced hyperparameters to the divided_hparams list\n",
    "        divided_hparams.append(slice_hparams)\n",
    "        \n",
    "        # Update the start_index for the next slice\n",
    "        start_index = end_index\n",
    "    \n",
    "    return divided_hparams\n",
    "\n",
    "\n",
    "def generate_json_files(num_tpus,tuning_search_space):\n",
    "    num_hparams_per_json = len(tuning_search_space)//num_tpus\n",
    "    # hparams_per_json_list = [num_hparams_per_json]*num_tpus\n",
    "    # if len(tuning_search_space)%num_tpus != 0:\n",
    "    #     hparams_per_json_list   += [len(tuning_search_space)%num_tpus ]\n",
    "    #list for caspr-adaptive\n",
    "    # hparams_per_json_list = [1,1,1,2,2,4,4]\n",
    "    # #list for shampoo\n",
    "    # hparams_per_json_list = [1,1,1,1,3,4,4]\n",
    "    # # list for nadamw 0.375\n",
    "    # hparams_per_json_list = [3,3,3,3,3]\n",
    "    # # list for nadamw 0.75\n",
    "    # hparams_per_json_list = [5,5,5]\n",
    "    # # list for adamw 0.75\n",
    "    # hparams_per_json_list = [5,5,5]\n",
    "    # # list for adamw 0.375\n",
    "    # hparams_per_json_list = [3,3,3,3,3]\n",
    "\n",
    "   \n",
    "    # #list for imagenet\n",
    "    # # list for caspr_adaptive (2tpuv2, 3tpuv3s)\n",
    "    # hparams_per_json_list = [2,2,3,4,4]\n",
    "\n",
    "    # #list for shampoo (3tpuv2, 2tpuv3s)\n",
    "    # hparams_per_json_list = [2,2,3,4,4]\n",
    "\n",
    "    #list for ogbg stack 2\n",
    "    # list for caspr_adaptive (2tpuv2, 3 tpuv3s)\n",
    "    hparams_per_json_list = [4,4,6,8,8]\n",
    "\n",
    "    num_tpus = len(hparams_per_json_list)\n",
    "    tuning_search_space = [ hparam._asdict() for hparam in tuning_search_space]\n",
    "    divided_hparams = divide_hparams(tuning_search_space,hparams_per_json_list)\n",
    "    print(\"divided_hparams \", [len(hparams) for hparams in divided_hparams])\n",
    "    for i in range(num_tpus):\n",
    "        hparams_in_json = divided_hparams[i]\n",
    "        # file_name = f\"caspr_adaptive_jsons/tuning_search_space_caspr_adaptive_{i}.json\"\n",
    "        # file_name = f\"shampoo_jsons/tuning_search_space_shampoo_{i}.json\"\n",
    "        # file_name = f\"adamw_0.375_jsons/tuning_search_space_adamw_0.375_{i}.json\"\n",
    "        # file_name = f\"caspr_adaptive_imagenet_jsons/tuning_search_space_caspr_adaptive_{i}.json\"\n",
    "        file_name = f\"caspr_adaptive_ogbg_stack_2_jsons/tuning_search_space_{i}.json\"\n",
    "        with open(file_name, 'w') as f:\n",
    "            json.dump(hparams_in_json, f, indent=4)\n",
    "\n",
    "\n",
    "# Adjust the `num_files` according to the number of TPUs you want to use\n",
    "num_tpus = 5  # Example, adjust as necessary\n",
    "generate_json_files(num_tpus,tuning_search_space)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
